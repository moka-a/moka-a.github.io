---
layout: post
title: "agera"
modified: 2015-12-20T23:39:55-04:00
categories: etc
excerpt:
tags: [android]
image:
  feature:
date: 2016-04-19T23:39:55-04:00
---

으로 인해 푸시 이벤트, 데이터 풀 모델과 일반적인 멀티 스레드 처리, 갱신 가능한이 저장소 데이터의 전체 변경 기록을 볼 수 없습니다. 이것은 의도적으로 설계된 동작입니다 : 대부분의 경우, 최신, 최신 데이터가 중요합니다 (특히 앱의 UI를 업데이트). 클라이언트해야 (최소 집합)이 변경의 전체 역사를 알고있는 경우, Agera은의 하위 유형 제공 저장소 : 저수지 , 이러한 시나리오에 유용 할 수 있습니다.

저수지는 큐의 반응 버전입니다. 데이터는 그 사용하여 저장 대기열 수 수신기 는 저수지의 사용 같은 데이터 디큐 다시 수의 클라이언트 updatables, 통지하는 원인이 인터페이스를 저장소 ( 공급 업체 인터페이스, 정확하기 참조). 저장소에 대한 액세스가 완전히 동기화되기 때문에, 두 개의 클라이언트 (인스턴스 여기 성공적 대기열 값으로 정의 된 데이터의 동일한 인스턴스를 큐에서 제거 할 수 없으며, 동일한 값 (동일한 Java 오브젝트 참조) 여러 번 대기열되면 그들은 저장조의 컨텍스트에서 다른 인스턴스)이다. 리턴 값 유형은로 싸여 결과 때문에 클라이언트는 저장소가 비어있을 때 데이터를 큐에서 제거하려고하면, 수신 할 수 Result.absent ()을 실패의 통지로.

이 동작으로, 저수지 데이터의 각 부분을 처리해야 몇 가지 반응의 데이터 소스 역할에 적합합니다. 반응에 사용하여 구현 될 수있다 컴파일 저장소 는 이벤트 소스의 하나로서 저장 사용을 적절하다면, 그와 함께 데이터 처리 흐름을 시작 .orSkip을 .attemptGetFrom (저장조 ()) . 저장이 컴파일 된 저장소 사이의 관찰-갱신 관계가 순차적으로 한 저장소가 활성화 될 때, 저수지에 제출 된 모든 데이터를 소비합니다.

단순 병렬 상술 한 방식에서의 이벤트 소스와 데이터 소스로 저장을 사용하는 각각의 저장조와 달리 동일한 컴파일 저장소의 다중 인스턴스를 사용하여 달성 될 수있다. 잡스는 저수지에 제출 될 수 있으며, 각 저장소는 별도의 데이터 처리 흐름에서 처리 작업을 대기열에서 제외하려고합니다. 이 저장소는 멀티 스레드 실행 프로그램에 처리를 이동하거나 다른 작업자 루퍼에서 실행해야합니다, 즉 실제 병렬 처리를 달성 할 수 있습니다.


Due to the push event, pull data model and the general multi-threaded handling, an updatable may not see the full change history of a repository’s data. This is by design: in most cases (particularly for updating the app’s UI), only the latest, most up-to-date data should matter. However, if the clients should (at least collectively) know the full history of changes, Agera provides a subtype of Repository: Reservoir, that can be useful for these scenarios.

push 이벤트, pull data 모델 그리고 일반적인 멀티쓰레드 처리 때문에 저장소 데이터의 전체 변경 이력을 알수 없을수도 있다. 대부분의 경우( 특히 앱의 UI 업데이트 )는 가장 최신의 데이터가 중요하다. 하지만 모든 변경 이력을 안다면  Agera 는 이러한 상황에서 유용한 저장소의 하위 개념인 Reservoir 을 제공한다.

Reservoir 은 큐의 반응형(reactive) 버전이다. 데이터는 Reservoir 에 들어갈수 있다.(enqueued)


A Reservoir is the reactive version of a Queue. Data can be enqueued to the reservoir using its Receiver interface, causing it to notify its client updatables, which can in turn dequeue the same data using the reservoir’s Repository (Supplier, to be precise) interface. Access to the reservoir is fully synchronized, so no two clients will be able to dequeue the same instance of data (an instance here is defined as a successfully enqueued value; if the same value (the same Java object reference) is enqueued multiple times, they are different instances in the context of a reservoir). The return value type is wrapped into a Result, so if a client attempts to dequeue data when the repository is empty, it can receive Result.absent() as a notice of failure.

With this behavior, a reservoir is perfect for acting as the data source of some reaction that must process each piece of data. The reaction can be implemented using a compiled repository if appropriate, that uses the reservoir as one of its event sources, and starts its data processing flow with .attemptGetFrom(reservoir).orSkip(). The observable-updatable relationship between the reservoir and this compiled repository will sequentially consume all data submitted to the reservoir, as long as the repository is activated.

Simple parallelism can be achieved using a reservoir and multiple instances of otherwise identical compiled repositories, each of which uses the reservoir as its event source and data source in the aforementioned manner. Jobs can be submitted to the reservoir, and each repository will attempt to dequeue the jobs for processing in their separate data processing flows. Note that to achieve actual parallelism, these repositories must move the processing onto a multi-threaded Executor, or run on different worker Loopers.
